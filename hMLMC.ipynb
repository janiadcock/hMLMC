{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate optimal sample allocation for Monte Carlo (MC)\n",
    "def MC(n_levels, V, epsilon_squared):\n",
    "    N_GPU = np.zeros(n_levels)\n",
    "    N_GPU[-1] = V[-1]/epsilon_squared\n",
    "    return N_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate optimal sample allocation for Multilevel Monte Carlo (MLMC)\n",
    "# M.B. Giles, 2018, Multilevel Monte Carlo methods, Acta Numerica, https://people.nps.ox.ac.uk/gilesm/files/acta15.pdf\n",
    "def MLMC(n_levels, V, C_GPU, epsilon_squared):\n",
    "    N_GPU = np.zeros(n_levels)\n",
    "    mu = 0.\n",
    "    for l in range(n_levels):\n",
    "        mu += np.sqrt(V[l]*C_GPU[l])\n",
    "    mu /= epsilon_squared\n",
    "    N_GPU = mu * np.sqrt(V/C_GPU)\n",
    "    return N_GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate optimal sample allocation for Multilevel Monte Carlo on Heterogeneous Computer Architectures (hMLMC)\n",
    "# C. Adcock, L. Jofre, G. Iaccarino, 2020, Multilevel Monte Carlo Sampling on Heterogenous Computer Architectures, \n",
    "#   International Journal for Uncertainty Quantification, \n",
    "#   http://www.dl.begellhouse.com.stanford.idm.oclc.org/journals/52034eb04b657aea,3673619972b2eee6,2dc1fd2d0ec3d1c0.html\n",
    "def hMLMC(n_levels, n_CPUs, n_GPUs, C_CPU, V, C_GPU, epsilon_squared):\n",
    "    # Step 1\n",
    "    alphas = np.sort(C_CPU/C_GPU*n_GPUs/n_CPUs, kind = 'quicksort') #quicksort is default\n",
    "    alpha_lb = alphas[0]\n",
    "    alpha_ub = alphas[n_levels - 1]\n",
    "    finished = False\n",
    "\n",
    "    while not finished:\n",
    "        # Step 2\n",
    "        alpha = (alpha_lb + alpha_ub)/2.\n",
    "        \n",
    "        # Step 3         \n",
    "        lambda_2 = 1./(1. + alpha)\n",
    "        lambda_3 = alpha/(1. + alpha)\n",
    "\n",
    "        # Step 4\n",
    "        lambda_1 = 0.\n",
    "        for l in range(n_levels):\n",
    "            lambda_1 += np.sqrt(V[l]/np.maximum(1./(lambda_2*C_CPU[l]*n_GPUs), \\\n",
    "                                            1./(lambda_3*C_GPU[l]*n_CPUs)))\n",
    "        lambda_1 /= epsilon_squared\n",
    "        lambda_1 = lambda_1**2\n",
    "\n",
    "        # Step 5\n",
    "        N_CPU = np.zeros(n_levels)\n",
    "        N_GPU = np.zeros(n_levels)\n",
    "\n",
    "        L_free = []\n",
    "        for l in range(n_levels):     \n",
    "            if math.isclose(lambda_3/lambda_2, C_CPU[l]/C_GPU[l]*n_GPUs/n_CPUs, rel_tol=1e-6):\n",
    "                L_free.append(l)          \n",
    "            elif lambda_3/lambda_2 > C_CPU[l]/C_GPU[l]*n_GPUs/n_CPUs:\n",
    "                # still N_GPU[l] = 0.\n",
    "                N_CPU[l] = np.sqrt((lambda_1*V[l])/(lambda_2*C_CPU[l]*n_GPUs))\n",
    "            else:\n",
    "                # lambda_3/lambda_2 < C_CPU[l]/C_GPU[l]*n_GPUs/n_CPUs:\n",
    "                N_GPU[l] = np.sqrt((lambda_1*V[l])/(lambda_3*C_GPU[l]*n_CPUs))\n",
    "                # still N_CPU[l] = 0.\n",
    "\n",
    "        # balance CPU and GPU cost using underconstrained N_l^C, N_l^G variables\n",
    "        # while ensuring N_l^C>0, N_l^G>0, and total variance = epsilon^2\n",
    "        for l in L_free:\n",
    "            C_CPU_total = np.sum(N_CPU*C_CPU)/n_CPUs\n",
    "            C_GPU_total = np.sum(N_GPU*C_GPU)/n_GPUs\n",
    "            N_l = np.sqrt((lambda_1*V[l])/(lambda_2*C_CPU[l]*n_GPUs))\n",
    "            # equivalently N_l = np.sqrt((lambda_1*V[l])/(lambda_3*C_GPU[l]))\n",
    "\n",
    "            if math.isclose(C_CPU_total, C_GPU_total):\n",
    "                N_CPU[l] = (N_l*C_GPU[l]*n_CPUs)/(C_CPU[l]*n_GPUs+C_GPU[l]*n_CPUs)\n",
    "                N_GPU[l] = (N_l*C_CPU[l]*n_GPUs)/(C_CPU[l]*n_GPUs+C_GPU[l]*n_CPUs)\n",
    "            elif C_CPU_total > C_GPU_total:\n",
    "                N_GPU_excess = n_GPUs/C_GPU[l]*(C_CPU_total - C_GPU_total)              \n",
    "                if N_GPU_excess >= N_l:\n",
    "                    N_GPU[l] = N_l\n",
    "                    # still N_CPU[l] = 0.\n",
    "                else:\n",
    "                    N_GPU[l] = N_GPU_excess\n",
    "                    N_to_split = N_l - N_GPU[l]\n",
    "                    N_CPU[l] = (N_to_split*C_GPU[l]*n_CPUs)/(C_CPU[l]*n_GPUs+C_GPU[l]*n_CPUs)\n",
    "                    N_GPU[l] += (N_to_split*C_CPU[l]*n_GPUs)/(C_CPU[l]*n_GPUs+C_GPU[l]*n_CPUs)\n",
    "            else:\n",
    "                # C_CPU_total < C_GPU_total\n",
    "                N_CPU_excess = n_CPUs/C_CPU[l]*(C_GPU_total - C_CPU_total)\n",
    "                if N_CPU_excess >= N_l:\n",
    "                    N_CPU[l] = N_l\n",
    "                    # still N_CPU[l] = 0.\n",
    "                else:\n",
    "                    N_CPU[l] = N_CPU_excess\n",
    "                    N_to_split = N_l - N_CPU[l]\n",
    "                    N_CPU[l] += (N_to_split*C_GPU[l]*n_CPUs)/(C_CPU[l]*n_GPUs+C_GPU[l]*n_CPUs)\n",
    "                    N_GPU[l] = (N_to_split*C_CPU[l]*n_GPUs)/(C_CPU[l]*n_GPUs+C_GPU[l]*n_CPUs)\n",
    "                    \n",
    "        # Step 6\n",
    "        C_CPU_total = np.sum(N_CPU*C_CPU)/n_CPUs\n",
    "        C_GPU_total = np.sum(N_GPU*C_GPU)/n_GPUs\n",
    "        \n",
    "        # Exit or prep for next iteration\n",
    "        if math.isclose(C_CPU_total, C_GPU_total):        \n",
    "            finished = True\n",
    "            break\n",
    "        elif C_CPU_total > C_GPU_total:\n",
    "            alpha_ub = alpha\n",
    "        else:\n",
    "            # C_CPU_total < C_GPU_total\n",
    "            alpha_lb = alpha\n",
    "    \n",
    "    return N_CPU, N_GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case\n",
    "Channel flow with stochastic heat flux BC (SoleilX)\n",
    "\n",
    "C. Adcock, L. Jofre, G. Iaccarino, 2020, Multilevel Monte Carlo Sampling on Heterogenous Computer Architectures, International Journal for Uncertainty Quantification, http://www.dl.begellhouse.com.stanford.idm.oclc.org/journals/52034eb04b657aea,3673619972b2eee6,2dc1fd2d0ec3d1c0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_CPUs = 792.*44.\n",
    "n_GPUs = 792.*4.\n",
    "\n",
    "# levels created by coarsening grid\n",
    "# grid points for each level: 64x32, 128x64, 128x128, 256x128, 512x128\n",
    "n_levels_all = 5\n",
    "\n",
    "# cost of running a sample on a CPU for each level\n",
    "C_CPU_all = np.array([628.602, 4389.38, 15448.9, 74334.2, 3.400593e+05])\n",
    "\n",
    "# cost of running a sample on a GPU for each level\n",
    "C_GPU_all = np.array([636.529, 2273.46, 4602.59, 11595.9, 2.804512e+04])\n",
    "\n",
    "# variance of each level, V[Q_l], where Q_l is a sample on level l\n",
    "V_Q_all = np.array([0.000182002, 0.000143691, 0.000108583, 0.000160483, 1.316855e-04])\n",
    "\n",
    "# variance of the difference between each level and the preceding level, V[Q_l - Q_{l-1}]\n",
    "V_dQ_all = np.array([np.nan, 1.64063e-05, 1.30941e-06, 1.05553e-06, 3.193399e-07])\n",
    "\n",
    "# tolerance on the variance\n",
    "epsilon_squared = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_CPU/C_GPU:  [ 0.99  1.93  3.36  6.41 12.13]\n",
      "\n",
      "Using finest 5 levels:\n",
      "N_GPU_MLMC:  [437.  69.  14.   8.   3.]\n",
      "N_CPU_hMLMC:  [683.  78.  12.   1.   0.]\n",
      "N_GPU_hMLMC:  [0. 0. 0. 4. 2.]\n",
      "tolerance:  1e-06\n",
      "V_MLMC:  9.9e-07\n",
      "V_hMLMC:  9.6e-07\n",
      "T_MLMC:  210.0\n",
      "T_hMLMC:  29.0\n",
      "T_hMLMC/T_MLMC:  0.14\n",
      "\n",
      "Using finest 4 levels:\n",
      "N_GPU_MLMC:  [215.  14.   8.   3.]\n",
      "N_CPU_hMLMC:  [259.  13.   0.   0.]\n",
      "N_GPU_hMLMC:  [0. 0. 6. 2.]\n",
      "tolerance:  1e-06\n",
      "V_MLMC:  1e-06\n",
      "V_hMLMC:  9.9e-07\n",
      "T_MLMC:  230.0\n",
      "T_hMLMC:  38.0\n",
      "T_hMLMC/T_MLMC:  0.17\n",
      "\n",
      "Using finest 3 levels:\n",
      "N_GPU_MLMC:  [140.   9.   3.]\n",
      "N_CPU_hMLMC:  [139.   0.   0.]\n",
      "N_GPU_hMLMC:  [2. 9. 3.]\n",
      "tolerance:  1e-06\n",
      "V_MLMC:  1e-06\n",
      "V_hMLMC:  9.9e-07\n",
      "T_MLMC:  263.0\n",
      "T_hMLMC:  61.0\n",
      "T_hMLMC/T_MLMC:  0.23\n",
      "\n",
      "Using finest 2 levels:\n",
      "N_GPU_MLMC:  [172.   5.]\n",
      "N_CPU_hMLMC:  [116.   0.]\n",
      "N_GPU_hMLMC:  [56.  5.]\n",
      "tolerance:  1e-06\n",
      "V_MLMC:  1e-06\n",
      "V_hMLMC:  1e-06\n",
      "T_MLMC:  672.0\n",
      "T_hMLMC:  247.0\n",
      "T_hMLMC/T_MLMC:  0.37\n",
      "\n",
      "Using finest 1 levels:\n",
      "N_GPU_MLMC:  [132.]\n",
      "N_CPU_hMLMC:  [63.]\n",
      "N_GPU_hMLMC:  [69.]\n",
      "tolerance:  1e-06\n",
      "V_MLMC:  1e-06\n",
      "V_hMLMC:  1e-06\n",
      "T_MLMC:  1166.0\n",
      "T_hMLMC:  611.0\n",
      "T_hMLMC/T_MLMC:  0.52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('C_CPU/C_GPU: ', np.round(C_CPU_all/C_GPU_all, 2))\n",
    "print('')\n",
    "for i in range(n_levels_all):\n",
    "    C_CPU = C_CPU_all[i:].copy()\n",
    "    C_GPU = C_GPU_all[i:].copy()\n",
    "    V = V_dQ_all[i:].copy()\n",
    "    V[0] = V_Q_all[i].copy()\n",
    "    \n",
    "    n_levels = n_levels_all-i\n",
    "    print('Using finest', n_levels, 'levels:')\n",
    "    \n",
    "    N_CPU_hMLMC, N_GPU_hMLMC = hMLMC(n_levels, n_CPUs, n_GPUs, C_CPU, V, C_GPU, epsilon_squared)\n",
    " \n",
    "    # number of samples to run on GPUs on each level for MLMC sample allocation\n",
    "    # note 1: this isn't necessarily just N_CPU_hMLMC + N_GPU_hMLMC\n",
    "    # note 2: MLMC assumes only one processor type; here assuming GPUs used since they're\n",
    "    #   typically faster than GPUs\n",
    "    N_GPU_MLMC = MLMC(n_levels, V, C_GPU, epsilon_squared)\n",
    "    print('N_GPU_MLMC: ', np.round(N_GPU_MLMC))\n",
    "    \n",
    "    # number of samples to run on CPUs on each level for hMLMC sample allocation\n",
    "    #   leftmost position is coarsest level\n",
    "    print('N_CPU_hMLMC: ', np.round(N_CPU_hMLMC))\n",
    "    \n",
    "    # number of samples to run on GPUs on each level for hMLMC sample allocation\n",
    "    print('N_GPU_hMLMC: ', np.round(N_GPU_hMLMC))\n",
    "\n",
    "    # variance--check that <= tolerance (epsilon_squared)\n",
    "    print('tolerance: ', epsilon_squared)\n",
    "    print ('V_MLMC: ', np.round(sum(V/(np.round(N_GPU_MLMC))), 8))\n",
    "    print('V_hMLMC: ', np.round(sum(V/(np.round(N_CPU_hMLMC)+np.round(N_GPU_hMLMC))), 8))\n",
    "    \n",
    "    # wall-clock time-to-solution\n",
    "    C_hMLMC = np.max([np.sum(C_CPU*N_CPU_hMLMC)/n_CPUs, np.sum(C_GPU*N_GPU_hMLMC)/n_GPUs])\n",
    "    C_MLMC = np.sum(C_GPU*N_GPU_MLMC)/n_GPUs\n",
    "    print('T_MLMC: ', np.round(C_MLMC, 0))\n",
    "    print('T_hMLMC: ', np.round(C_hMLMC, 0))\n",
    "    print('T_hMLMC/T_MLMC: ', np.round(C_hMLMC/C_MLMC,2))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
